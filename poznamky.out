\BOOKMARK [1][-]{section.1}{Dopredn\351 modely. Ot\341zky 1 a\236 7. }{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Strucn\341 hist\363ria konekcionizmu, vlastnosti biologick\351ho neur\363nu, model neur\363nu s prahovou logikou, implement\341cia Booleov\375ch funkci\355. Paradigmy ucenia a typy \372loh pre NS.}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Bin\341rny perceptr\363n: pojem ucenia s ucitelom, uciace pravidlo, algoritmus tr\351novania, deliaca nadrovina, klasifik\341cia vzorov, line\341rna separovatelnost, n\341crt d\364kazu konvergencie, defin\355cia a pr\355klad.}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Spojit\375 perceptr\363n: R\364zne aktivacn\351 funkcie perceptr\363nu, chybov\341 funkcia a sp\364sob jej minimaliz\341cie, uciace pravidlo, algoritmus tr\351novania perceptr\363nu. S\372vis s Bayesovsk\375m klasifik\341torom.}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Viacvrstvov\351 dopredn\351 neur\363nov\351 siete: architekt\372ra a aktivacn\351 vzorce, odvodenie met\363dy ucenia pomocou sp\344tn\351ho \235\355renia ch\375b \(BP\) pre dvojvrstvov\372 dopredn\372 NS, modifik\341cie BP, typy \372loh pre pou\236itie doprednej NS.}{section.1}% 5
\BOOKMARK [2][-]{subsection.1.5}{Viacvrstvov\341 dopredn\341 NS ako univerz\341lny aproxim\341tor funkci\355 \(formul\341cia teor\351mu\), tr\351novacia a testovacia mno\236ina, generaliz\341cia, preucenie, skor\351 zastavenie ucenia, selekcia modelu, valid\341cia modelu. Hlbok\351 ucenie NS.}{section.1}% 6
\BOOKMARK [2][-]{subsection.1.6}{Line\341rne modely NS: vztah pre rie\235enie syst\351mu lin. rovn\355c v jednovrstvovej sieti, pojem pseudoinverzie matice, autoasociat\355vna pam\344t: line\341rny obal, princ\355p funkcie modelu, detektor novosti.}{section.1}% 7
\BOOKMARK [2][-]{subsection.1.7}{Line\341rne modely NS: \372cel Grammovho-Schmidtovho ortogonalizacn\351ho procesu, GI model. Pam\344t korelacnej matice ako autoasociat\355vna pam\344t, vztah pre v\375pocet v\341h, presluch, porovnanie s GI.}{section.1}% 8
\BOOKMARK [1][-]{section.2}{Samoorganiz\341cia a RBF siet. Ot\341zky 8 a\236 12.}{}% 9
\BOOKMARK [2][-]{subsection.2.1}{Samoorganiz\341cia v NS, z\341kladn\351 princ\355py, pojem ucenia bez ucitela, typy \372loh pou\236itia, Ojovo pravidlo ucenia pre jeden neur\363n, vysvetlenie konvergencie.}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.2}{Met\363da hlavn\375ch komponentov pomocou algoritmu GHA a APEX, architekt\372ra modelu, vztah pre adapt\341ciu v\341h, pojem vlastn\375ch vektorov a vlastn\375ch c\355sel, redukcia dimenzie, aplik\341cia na kompresiu obrazu.}{section.2}% 11
\BOOKMARK [2][-]{subsection.2.3}{Ucenie so s\372ta\236en\355m \(typu \215winner-take-all\216\), nev\375hody. Neurobiologick\341 motiv\341cia algoritmu SOM, later\341lna interakcia a jej n\341hrada v SOM, sumariz\341cia algoritmu, volba parametrov modelu.}{section.2}% 12
\BOOKMARK [2][-]{subsection.2.4}{SOM: vektorov\341 kvantiz\341cia, topografick\351 zobrazenie pr\355znakov, algoritmus SOM, parametre, redukcia dimenzie, magnifikacn\341 vlastnost, pr\355klad pou\236itia.}{section.2}% 13
\BOOKMARK [2][-]{subsection.2.5}{Hybridn\351 modely NS, RBF model: aktivacn\351 vzorce, b\341zov\351 funkcie, pr\355znakov\375 priestor, probl\351m interpol\341cie, tr\351novanie modelu, aproximacn\351 vlastnosti RBF siete.}{section.2}% 14
\BOOKMARK [1][-]{section.3}{Rekurentn\351 a pam\344tov\351 modely. Ot\341zky 13 a\236 18.}{}% 15
\BOOKMARK [2][-]{subsection.3.1}{NS na spracovanie sekvencn\375ch d\341t: reprezent\341cia casu, typy \372loh pre rekurentn\351 NS. Modely s casov\375m oknom do minulosti, v\375hody a nedostatky, pr\355klad pou\236itia.}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.2}{Rekurentn\351 NS: princ\355p tr\351novania pomocou algoritmu BPTT a RTRL. Pr\355klad pou\236itia.}{section.3}% 17
\BOOKMARK [2][-]{subsection.3.3}{Elmanova siet: intern\351 reprezent\341cie pri symbolovej dynamike, Markovovsk\351 spr\341vanie, architektur\341lna predispoz\355cia. Model rekurz\355vnej SOM \(RecSOM\).}{section.3}% 18
\BOOKMARK [2][-]{subsection.3.4}{Siet s echo stavmi \(ESN\): architekt\372ra, inicializ\341cia, tr\351novanie modelu, vplyv parametrov na vlastnosti rezervo\341ra, echo vlastnost, pam\344tov\341 kapacita.}{section.3}% 19
\BOOKMARK [2][-]{subsection.3.5}{Hopfieldov model NS: deterministick\341 dynamika, energia syst\351mu, relax\341cia, typy atraktorov, autoasociat\355vna pam\344t \205 nastavenie v\341h, princ\355p v\375poctu kapacity pam\344te.}{section.3}% 20
\BOOKMARK [2][-]{subsection.3.6}{Neline\341rne dynamick\351 syst\351my: stavov\375 portr\351t, dynamika, typy atraktorov. Hopfieldov model NS: stochastick\341 dynamika, parameter inverznej teploty, princ\355p odstr\341nenia falo\235n\375ch atraktorov.}{section.3}% 21
