\select@language {english}
\contentsline {section}{\numberline {1}Dopredn\IeC {\'e} modely. Ot\IeC {\'a}zky 1 a\IeC {\v z} 7. }{3}{section.1}
\contentsline {subsection}{\numberline {1.1}Stru\IeC {\v c}n\IeC {\'a} hist\IeC {\'o}ria konekcionizmu, vlastnosti biologick\IeC {\'e}ho neur\IeC {\'o}nu, model neur\IeC {\'o}nu s prahovou logikou, implement\IeC {\'a}cia Booleov\IeC {\'y}ch funkci\IeC {\'\i }. Paradigmy u\IeC {\v c}enia a typy \IeC {\'u}loh pre NS.}{3}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Bin\IeC {\'a}rny perceptr\IeC {\'o}n: pojem u\IeC {\v c}enia s u\IeC {\v c}ite\IeC {\v l}om, u\IeC {\v c}iace pravidlo, algoritmus tr\IeC {\'e}novania, deliaca nadrovina, klasifik\IeC {\'a}cia vzorov, line\IeC {\'a}rna separovate\IeC {\v l}nos\IeC {\v t}, n\IeC {\'a}\IeC {\v c}rt d\IeC {\^o}kazu konvergencie, defin\IeC {\'\i }cia a pr\IeC {\'\i }klad.}{4}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Spojit\IeC {\'y} perceptr\IeC {\'o}n: R\IeC {\^o}zne aktiva\IeC {\v c}n\IeC {\'e} funkcie perceptr\IeC {\'o}nu, chybov\IeC {\'a} funkcia a sp\IeC {\^o}sob jej minimaliz\IeC {\'a}cie, u\IeC {\v c}iace pravidlo, algoritmus tr\IeC {\'e}novania perceptr\IeC {\'o}nu. S\IeC {\'u}vis s Bayesovsk\IeC {\'y}m klasifik\IeC {\'a}torom.}{5}{subsection.1.3}
\contentsline {subsection}{\numberline {1.4}Viacvrstvov\IeC {\'e} dopredn\IeC {\'e} neur\IeC {\'o}nov\IeC {\'e} siete: architekt\IeC {\'u}ra a aktiva\IeC {\v c}n\IeC {\'e} vzorce, odvodenie met\IeC {\'o}dy u\IeC {\v c}enia pomocou sp\IeC {\"a}tn\IeC {\'e}ho \IeC {\v s}\IeC {\'\i }renia ch\IeC {\'y}b (BP) pre dvojvrstvov\IeC {\'u} dopredn\IeC {\'u} NS, modifik\IeC {\'a}cie BP, typy \IeC {\'u}loh pre pou\IeC {\v z}itie doprednej NS.}{7}{subsection.1.4}
\contentsline {subsection}{\numberline {1.5}Viacvrstvov\IeC {\'a} dopredn\IeC {\'a} NS ako univerz\IeC {\'a}lny aproxim\IeC {\'a}tor funkci\IeC {\'\i } (formul\IeC {\'a}cia teor\IeC {\'e}mu), tr\IeC {\'e}novacia a testovacia mno\IeC {\v z}ina, generaliz\IeC {\'a}cia, preu\IeC {\v c}enie, skor\IeC {\'e} zastavenie u\IeC {\v c}enia, selekcia modelu, valid\IeC {\'a}cia modelu. Hlbok\IeC {\'e} u\IeC {\v c}enie NS.}{8}{subsection.1.5}
\contentsline {subsection}{\numberline {1.6}Line\IeC {\'a}rne modely NS: vz\IeC {\v t}ah pre rie\IeC {\v s}enie syst\IeC {\'e}mu lin. rovn\IeC {\'\i }c v jednovrstvovej sieti, pojem pseudoinverzie matice, autoasociat\IeC {\'\i }vna pam\IeC {\"a}\IeC {\v t}: line\IeC {\'a}rny obal, princ\IeC {\'\i }p funkcie modelu, detektor novosti.}{10}{subsection.1.6}
\contentsline {subsection}{\numberline {1.7}Line\IeC {\'a}rne modely NS: \IeC {\'u}\IeC {\v c}el Grammovho-Schmidtovho ortogonaliza\IeC {\v c}n\IeC {\'e}ho procesu, GI model. Pam\IeC {\"a}\IeC {\v t} korela\IeC {\v c}nej matice ako autoasociat\IeC {\'\i }vna pam\IeC {\"a}\IeC {\v t}, vz\IeC {\v t}ah pre v\IeC {\'y}po\IeC {\v c}et v\IeC {\'a}h, presluch, porovnanie s GI.}{11}{subsection.1.7}
\contentsline {section}{\numberline {2}Samoorganiz\IeC {\'a}cia a RBF sie\IeC {\v t}. Ot\IeC {\'a}zky 8 a\IeC {\v z} 12.}{11}{section.2}
\contentsline {subsection}{\numberline {2.1}Samoorganiz\IeC {\'a}cia v NS, z\IeC {\'a}kladn\IeC {\'e} princ\IeC {\'\i }py, pojem u\IeC {\v c}enia bez u\IeC {\v c}ite\IeC {\v l}a, typy \IeC {\'u}loh pou\IeC {\v z}itia, Ojovo pravidlo u\IeC {\v c}enia pre jeden neur\IeC {\'o}n, vysvetlenie konvergencie.}{11}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Met\IeC {\'o}da hlavn\IeC {\'y}ch komponentov pomocou algoritmu GHA a APEX, architekt\IeC {\'u}ra modelu, vz\IeC {\v t}ah pre adapt\IeC {\'a}ciu v\IeC {\'a}h, pojem vlastn\IeC {\'y}ch vektorov a vlastn\IeC {\'y}ch \IeC {\v c}\IeC {\'\i }sel, redukcia dimenzie, aplik\IeC {\'a}cia na kompresiu obrazu.}{12}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}U\IeC {\v c}enie so s\IeC {\'u}\IeC {\v t}a\IeC {\v z}en\IeC {\'\i }m (typu \IeC {\textquotedblleft }winner-take-all\IeC {\textquotedblright }), nev\IeC {\'y}hody. Neurobiologick\IeC {\'a} motiv\IeC {\'a}cia algoritmu SOM, later\IeC {\'a}lna interakcia a jej n\IeC {\'a}hrada v SOM, sumariz\IeC {\'a}cia algoritmu, vo\IeC {\v l}ba parametrov modelu.}{13}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}SOM: vektorov\IeC {\'a} kvantiz\IeC {\'a}cia, topografick\IeC {\'e} zobrazenie pr\IeC {\'\i }znakov, algoritmus SOM, parametre, redukcia dimenzie, magnifika\IeC {\v c}n\IeC {\'a} vlastnos\IeC {\v t}, pr\IeC {\'\i }klad pou\IeC {\v z}itia.}{15}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Hybridn\IeC {\'e} modely NS, RBF model: aktiva\IeC {\v c}n\IeC {\'e} vzorce, b\IeC {\'a}zov\IeC {\'e} funkcie, pr\IeC {\'\i }znakov\IeC {\'y} priestor, probl\IeC {\'e}m interpol\IeC {\'a}cie, tr\IeC {\'e}novanie modelu, aproxima\IeC {\v c}n\IeC {\'e} vlastnosti RBF siete.}{17}{subsection.2.5}
\contentsline {section}{\numberline {3}Rekurentn\IeC {\'e} a pam\IeC {\"a}\IeC {\v t}ov\IeC {\'e} modely. Ot\IeC {\'a}zky 13 a\IeC {\v z} 18.}{19}{section.3}
\contentsline {subsection}{\numberline {3.1}NS na spracovanie sekven\IeC {\v c}n\IeC {\'y}ch d\IeC {\'a}t: reprezent\IeC {\'a}cia \IeC {\v c}asu, typy \IeC {\'u}loh pre rekurentn\IeC {\'e} NS. Modely s \IeC {\v c}asov\IeC {\'y}m oknom do minulosti, v\IeC {\'y}hody a nedostatky, pr\IeC {\'\i }klad pou\IeC {\v z}itia.}{19}{subsection.3.1}
\contentsline {subsubsection}{\numberline {3.1.1}Nerekurentn\IeC {\'e} modely}{19}{subsubsection.3.1.1}
\contentsline {subsection}{\numberline {3.2}Rekurentn\IeC {\'e} NS: princ\IeC {\'\i }p tr\IeC {\'e}novania pomocou algoritmu BPTT a RTRL. Pr\IeC {\'\i }klad pou\IeC {\v z}itia.}{20}{subsection.3.2}
\contentsline {subsubsection}{\numberline {3.2.1}Back-propagation through time - BPTT}{21}{subsubsection.3.2.1}
\contentsline {subsubsection}{\numberline {3.2.2}Real-time recurrent learning - RTRL}{22}{subsubsection.3.2.2}
\contentsline {subsection}{\numberline {3.3}Elmanova sie\IeC {\v t}: intern\IeC {\'e} reprezent\IeC {\'a}cie pri symbolovej dynamike, Markovovsk\IeC {\'e} spr\IeC {\'a}vanie, architektur\IeC {\'a}lna predispoz\IeC {\'\i }cia. Model rekurz\IeC {\'\i }vnej SOM (RecSOM).}{22}{subsection.3.3}
\contentsline {subsection}{\numberline {3.4}Sie\IeC {\v t} s echo stavmi (ESN): architekt\IeC {\'u}ra, inicializ\IeC {\'a}cia, tr\IeC {\'e}novanie modelu, vplyv parametrov na vlastnosti rezervo\IeC {\'a}ra, echo vlastnos\IeC {\v t}, pam\IeC {\"a}\IeC {\v t}ov\IeC {\'a} kapacita.}{22}{subsection.3.4}
\contentsline {subsection}{\numberline {3.5}Hopfieldov model NS: deterministick\IeC {\'a} dynamika, energia syst\IeC {\'e}mu, relax\IeC {\'a}cia, typy atraktorov, autoasociat\IeC {\'\i }vna pam\IeC {\"a}\IeC {\v t} \IeC {\textendash } nastavenie v\IeC {\'a}h, princ\IeC {\'\i }p v\IeC {\'y}po\IeC {\v c}tu kapacity pam\IeC {\"a}te.}{23}{subsection.3.5}
\contentsline {subsection}{\numberline {3.6}Neline\IeC {\'a}rne dynamick\IeC {\'e} syst\IeC {\'e}my: stavov\IeC {\'y} portr\IeC {\'e}t, dynamika, typy atraktorov. Hopfieldov model NS: stochastick\IeC {\'a} dynamika, parameter inverznej teploty, princ\IeC {\'\i }p odstr\IeC {\'a}nenia falo\IeC {\v s}n\IeC {\'y}ch atraktorov.}{25}{subsection.3.6}
